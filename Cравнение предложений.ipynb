{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In comparison to dogs, cats have not undergone major changes during the domestication process.\r\n",
      "As cat simply catenates streams of bytes, it can be also used to concatenate binary files, where it will just concatenate sequence of bytes.\r\n",
      "A common interactive use of cat for a single file is to output the content of a file to standard output.\r\n",
      "Cats can hear sounds too faint or too high in frequency for human ears, such as those made by mice and other small animals.\r\n",
      "In one, people deliberately tamed cats in a process of artificial selection, as they were useful predators of vermin.\r\n",
      "The domesticated cat and its closest wild ancestor are both diploid organisms that possess 38 chromosomes and roughly 20,000 genes.\r\n",
      "Domestic cats are similar in size to the other members of the genus Felis, typically weighing between 4 and 5 kg (8.8 and 11.0 lb).\r\n",
      "However, if the output is piped or redirected, cat is unnecessary.\r\n",
      "cat with one named file is safer where human error is a concern - one wrong use of the default redirection symbol \">\" instead of \"<\" (often adjacent on keyboards) may permanently delete the file you were just needing to read.\r\n",
      "In terms of legibility, a sequence of commands starting with cat and connected by pipes has a clear left-to-right flow of information.\r\n"
     ]
    }
   ],
   "source": [
    "!head sentences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('sentences.txt') as file_:\n",
    "    sentences = file_.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая строка в файле соответствует одному предложению. Считайте их, приведите каждую к нижнему регистру с помощью строковой функции lower()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = sentences.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведите токенизацию, то есть разбиение текстов на слова. Для этого можно воспользоваться регулярным выражением, которое считает разделителем любой символ, не являющийся буквой: re.split('[^a-z]', t). Не забудьте удалить пустые слова после разделения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = [s for s in re.split('\\.\\n', sentences) if s != '']\n",
    "# Получен список предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized_sent = [re.split('[^a-z]', s) for s in sentences]\n",
    "# предложения токенизированы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = []\n",
    "for tok in tokenized_sent:\n",
    "    tokenized_sentences.append([i for i in tok if i != ''])\n",
    "# удалены пустые токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenized_sentences = []\n",
    "# for sentence in sentences:\n",
    "#     tokens = re.split('[^a-z]', sentence)\n",
    "#     tokenized_sentences.append(filter(lambda t : t != \"\", tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте список всех слов, встречающихся в предложениях. Сопоставьте каждому слову индекс от нуля до (d - 1), где d — число различных слов в предложениях. Для этого удобно воспользоваться структурой dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = [word for sent in tokenized_sentences for word in sent]\n",
    "uniq_words = set(words)\n",
    "# составлен список уникальных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_dict = dict()\n",
    "\n",
    "for numb, i in enumerate(uniq_words):\n",
    "    word_dict[i] = numb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_dict = {}\n",
    "\n",
    "# word_id = 0\n",
    "# for word in words:\n",
    "#     if word not in word_dict:\n",
    "#         word_dict[word] = word_id\n",
    "#         word_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 232,\n",
       " 'according': 98,\n",
       " 'adjacent': 211,\n",
       " 'allow': 248,\n",
       " 'allows': 97,\n",
       " 'also': 208,\n",
       " 'an': 188,\n",
       " 'ancestor': 215,\n",
       " 'and': 177,\n",
       " 'animals': 164,\n",
       " 'any': 196,\n",
       " 'app': 114,\n",
       " 'apple': 113,\n",
       " 'are': 58,\n",
       " 'arguments': 210,\n",
       " 'artificial': 68,\n",
       " 'as': 190,\n",
       " 'available': 51,\n",
       " 'based': 88,\n",
       " 'basic': 138,\n",
       " 'be': 79,\n",
       " 'between': 72,\n",
       " 'binary': 199,\n",
       " 'both': 91,\n",
       " 'by': 90,\n",
       " 'bytes': 42,\n",
       " 'can': 172,\n",
       " 'cat': 170,\n",
       " 'catenates': 106,\n",
       " 'cats': 136,\n",
       " 'changes': 107,\n",
       " 'chromosomes': 218,\n",
       " 'clear': 239,\n",
       " 'closest': 219,\n",
       " 'command': 246,\n",
       " 'commands': 92,\n",
       " 'common': 77,\n",
       " 'community': 115,\n",
       " 'comparison': 230,\n",
       " 'computers': 179,\n",
       " 'concatenate': 78,\n",
       " 'concern': 62,\n",
       " 'connected': 227,\n",
       " 'contains': 148,\n",
       " 'content': 69,\n",
       " 'count': 162,\n",
       " 'create': 130,\n",
       " 'default': 167,\n",
       " 'delete': 125,\n",
       " 'deliberately': 25,\n",
       " 'developed': 5,\n",
       " 'diploid': 85,\n",
       " 'disk': 15,\n",
       " 'displays': 0,\n",
       " 'dogs': 141,\n",
       " 'domestic': 8,\n",
       " 'domesticated': 195,\n",
       " 'domestication': 197,\n",
       " 'download': 60,\n",
       " 'drive': 22,\n",
       " 'during': 37,\n",
       " 'ears': 50,\n",
       " 'editions': 155,\n",
       " 'enhancements': 127,\n",
       " 'entirely': 48,\n",
       " 'error': 63,\n",
       " 'every': 33,\n",
       " 'external': 154,\n",
       " 'factory': 67,\n",
       " 'faint': 111,\n",
       " 'features': 18,\n",
       " 'felis': 109,\n",
       " 'fifth': 17,\n",
       " 'file': 192,\n",
       " 'files': 144,\n",
       " 'firmware': 205,\n",
       " 'flow': 241,\n",
       " 'for': 64,\n",
       " 'frequency': 57,\n",
       " 'from': 126,\n",
       " 'genes': 81,\n",
       " 'genus': 234,\n",
       " 'has': 27,\n",
       " 'have': 180,\n",
       " 'hear': 153,\n",
       " 'high': 189,\n",
       " 'however': 135,\n",
       " 'human': 13,\n",
       " 'if': 198,\n",
       " 'in': 193,\n",
       " 'incremental': 191,\n",
       " 'information': 220,\n",
       " 'installation': 93,\n",
       " 'installed': 10,\n",
       " 'installs': 94,\n",
       " 'instead': 213,\n",
       " 'intel': 40,\n",
       " 'interactive': 176,\n",
       " 'is': 184,\n",
       " 'it': 187,\n",
       " 'its': 16,\n",
       " 'july': 99,\n",
       " 'just': 4,\n",
       " 'keyboards': 41,\n",
       " 'kg': 235,\n",
       " 'later': 100,\n",
       " 'lb': 21,\n",
       " 'learned': 74,\n",
       " 'left': 253,\n",
       " 'legibility': 203,\n",
       " 'leopard': 223,\n",
       " 'lines': 183,\n",
       " 'linux': 121,\n",
       " 'lion': 56,\n",
       " 'longer': 161,\n",
       " 'mac': 101,\n",
       " 'made': 163,\n",
       " 'major': 110,\n",
       " 'marks': 26,\n",
       " 'mavericks': 165,\n",
       " 'may': 221,\n",
       " 'members': 86,\n",
       " 'mice': 157,\n",
       " 'mid': 207,\n",
       " 'more': 143,\n",
       " 'most': 225,\n",
       " 'mountain': 178,\n",
       " 'moved': 186,\n",
       " 'named': 9,\n",
       " 'need': 194,\n",
       " 'needing': 96,\n",
       " 'new': 73,\n",
       " 'no': 201,\n",
       " 'non': 29,\n",
       " 'not': 36,\n",
       " 'now': 38,\n",
       " 'october': 32,\n",
       " 'of': 95,\n",
       " 'off': 156,\n",
       " 'offered': 216,\n",
       " 'often': 53,\n",
       " 'on': 52,\n",
       " 'one': 116,\n",
       " 'online': 212,\n",
       " 'or': 108,\n",
       " 'organisms': 236,\n",
       " 'os': 34,\n",
       " 'osx': 1,\n",
       " 'other': 209,\n",
       " 'output': 47,\n",
       " 'over': 6,\n",
       " 'part': 152,\n",
       " 'patch': 44,\n",
       " 'people': 131,\n",
       " 'permanently': 139,\n",
       " 'piped': 76,\n",
       " 'pipes': 65,\n",
       " 'place': 247,\n",
       " 'possess': 39,\n",
       " 'predators': 45,\n",
       " 'predecessor': 28,\n",
       " 'process': 182,\n",
       " 'processors': 200,\n",
       " 'purchase': 233,\n",
       " 'rather': 202,\n",
       " 'read': 31,\n",
       " 'received': 185,\n",
       " 'receives': 104,\n",
       " 'recent': 231,\n",
       " 'redirected': 250,\n",
       " 'redirection': 134,\n",
       " 'release': 84,\n",
       " 'released': 151,\n",
       " 'releases': 145,\n",
       " 'releasing': 149,\n",
       " 'right': 119,\n",
       " 'roughly': 242,\n",
       " 'run': 71,\n",
       " 'running': 117,\n",
       " 's': 102,\n",
       " 'safari': 3,\n",
       " 'safer': 89,\n",
       " 'second': 128,\n",
       " 'selection': 2,\n",
       " 'separate': 204,\n",
       " 'sequence': 54,\n",
       " 'similar': 175,\n",
       " 'simply': 120,\n",
       " 'since': 66,\n",
       " 'single': 169,\n",
       " 'size': 123,\n",
       " 'small': 46,\n",
       " 'so': 243,\n",
       " 'some': 55,\n",
       " 'sounds': 122,\n",
       " 'standard': 83,\n",
       " 'started': 147,\n",
       " 'starting': 238,\n",
       " 'stdin': 240,\n",
       " 'stdout': 181,\n",
       " 'store': 142,\n",
       " 'streams': 103,\n",
       " 'successor': 105,\n",
       " 'such': 229,\n",
       " 'switch': 244,\n",
       " 'symbol': 222,\n",
       " 'symbols': 11,\n",
       " 't': 133,\n",
       " 'tamed': 19,\n",
       " 'terms': 61,\n",
       " 'than': 159,\n",
       " 'that': 146,\n",
       " 'the': 251,\n",
       " 'their': 129,\n",
       " 'they': 35,\n",
       " 'those': 160,\n",
       " 'three': 75,\n",
       " 'through': 12,\n",
       " 'tiger': 150,\n",
       " 'time': 249,\n",
       " 'to': 23,\n",
       " 'too': 137,\n",
       " 'two': 132,\n",
       " 'type': 140,\n",
       " 'typically': 252,\n",
       " 'undergone': 124,\n",
       " 'unix': 118,\n",
       " 'unnecessary': 43,\n",
       " 'update': 224,\n",
       " 'upgrade': 20,\n",
       " 'use': 82,\n",
       " 'used': 217,\n",
       " 'useful': 112,\n",
       " 'using': 237,\n",
       " 'vermin': 7,\n",
       " 'version': 70,\n",
       " 'versions': 166,\n",
       " 'was': 168,\n",
       " 'weighing': 80,\n",
       " 'were': 173,\n",
       " 'when': 206,\n",
       " 'where': 49,\n",
       " 'which': 30,\n",
       " 'wild': 174,\n",
       " 'will': 171,\n",
       " 'with': 158,\n",
       " 'without': 245,\n",
       " 'won': 24,\n",
       " 'world': 14,\n",
       " 'wrong': 226,\n",
       " 'x': 87,\n",
       " 'year': 59,\n",
       " 'yosemite': 228,\n",
       " 'you': 214}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_sentences = []\n",
    "for tok in tokenized_sentences:\n",
    "    temp_sentences.append([word_dict[word] for word in tok])\n",
    "# шифруем предложения нашими числовыми значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[193, 230, 23, 141, 136, 180, 36, 124, 110, 107, 37, 251, 197, 182]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_sentences[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте матрицу размера n X d, где n — число предложений. Заполните ее: элемент с индексом (i, j) в этой матрице должен быть равен количеству вхождений j-го слова в i-е предложение. У вас должна получиться матрица размера 22 * 254."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_matrix = np.zeros((len(sentences), len(uniq_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 254)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_matrix.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = sentence\n",
    "j = word\n",
    "value = Counter(tokenized_sentences[0])['cats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for num_sentence, sentence in enumerate(temp_sentences):\n",
    "    counter_dict = Counter(sentence)\n",
    "    for word in sentence:\n",
    "        value = counter_dict[word]\n",
    "        sent_matrix[num_sentence, word] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 254)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_matrix[21][np.newaxis, : ].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите косинусное расстояние от предложения в самой первой строке (In comparison to dogs, cats have not undergone...) до всех остальных с помощью функции scipy.spatial.distance.cosine. Какие номера у двух предложений, ближайших к нему по этому расстоянию (строки нумеруются с нуля)? Эти два числа и будут ответами на задание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "# косинусное расстояние. Чем меньше, тем сильнее схожи 2 предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cos_vectors = []\n",
    "\n",
    "for i in sent_matrix:\n",
    "    cos_vectors.append(cosine(sent_matrix[0], i))\n",
    "#     print cosine(sent_matrix[0], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.95275444087384664,\n",
       " 0.86447381456421235,\n",
       " 0.89517151632780823,\n",
       " 0.77708871496985887,\n",
       " 0.94023856953328033,\n",
       " 0.7327387580875756,\n",
       " 0.92587506833388988,\n",
       " 0.88427248752843102,\n",
       " 0.90550888174769317,\n",
       " 0.83281653622739416,\n",
       " 0.88047713906656067,\n",
       " 0.83964325485254543,\n",
       " 0.87035925528956715,\n",
       " 0.87401184233025764,\n",
       " 0.94427217874246472,\n",
       " 0.84063618542208085,\n",
       " 0.95664450152379399,\n",
       " 0.94427217874246472,\n",
       " 0.88854435748492944,\n",
       " 0.84275727449171223,\n",
       " 0.82503644694405864]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_vec = sorted(cos_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7327387580875756, 0.77708871496985887]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vec[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "close_sent = []\n",
    "c = 0\n",
    "for i in cos_vectors:\n",
    "    c += 1\n",
    "    if i in sorted_vec[1:3]:\n",
    "        close_sent.append(c-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.argsort(cos_vectors)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from operator import itemgetter\n",
    "\n",
    "# sorted(enumerate(cos_vectors), key=itemgetter(1))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'comparison', 'to', 'dogs', 'cats', 'have', 'not', 'undergone', 'major', 'changes', 'during', 'the', 'domestication', 'process']\n",
      "['in', 'one', 'people', 'deliberately', 'tamed', 'cats', 'in', 'a', 'process', 'of', 'artificial', 'selection', 'as', 'they', 'were', 'useful', 'predators', 'of', 'vermin']\n",
      "['domestic', 'cats', 'are', 'similar', 'in', 'size', 'to', 'the', 'other', 'members', 'of', 'the', 'genus', 'felis', 'typically', 'weighing', 'between', 'and', 'kg', 'and', 'lb']\n"
     ]
    }
   ],
   "source": [
    "print tokenized_sentences[0]\n",
    "for i in close_sent:\n",
    "    print tokenized_sentences[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совпадают ли ближайшие два предложения по тематике с первым? Совпадают ли тематики у следующих по близости предложений?\n",
    "\n",
    "> ближайшие 2 предложения совпадают по тематике с первым (тема: коты), но следующие по близости уже нет (тема: мак ос)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "true_vectors = []\n",
    "\n",
    "for i in sent_matrix:\n",
    "    true_vectors.append(float(cosine_similarity(sent_matrix[0][np.newaxis, : ], i[np.newaxis, : ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17496355]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sent_matrix[0][np.newaxis, : ], i[np.newaxis, : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_true_sent = []\n",
    "c = 0\n",
    "for i in true_vectors:\n",
    "    c += 1\n",
    "    if i in sorted(true_vectors, reverse=True)[1:3]:\n",
    "        close_true_sent.append(c-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6]\n",
      "['in', 'comparison', 'to', 'dogs', 'cats', 'have', 'not', 'undergone', 'major', 'changes', 'during', 'the', 'domestication', 'process']\n",
      "['in', 'one', 'people', 'deliberately', 'tamed', 'cats', 'in', 'a', 'process', 'of', 'artificial', 'selection', 'as', 'they', 'were', 'useful', 'predators', 'of', 'vermin']\n",
      "['domestic', 'cats', 'are', 'similar', 'in', 'size', 'to', 'the', 'other', 'members', 'of', 'the', 'genus', 'felis', 'typically', 'weighing', 'between', 'and', 'kg', 'and', 'lb']\n"
     ]
    }
   ],
   "source": [
    "print close_true_sent\n",
    "\n",
    "print tokenized_sentences[0]\n",
    "for i in close_true_sent:\n",
    "    print tokenized_sentences[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
